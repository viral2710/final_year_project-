{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img      object\n",
      "ang     float64\n",
      "date     object\n",
      "time     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(r'C:\\Users\\viral\\Desktop\\final_project\\myproject\\dataset\\label.csv')\n",
    "print(data_df.dtypes)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load training data and split it into training and validation set\n",
    "    \n",
    "    \"\"\"\n",
    "    #reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(r'C:\\Users\\viral\\Desktop\\final_project\\myproject\\dataset\\label.csv', names=['img', 'ang', 'date', 'time'])\n",
    "    #yay dataframes, we can select rows and columns by their names\n",
    "    #we'll store the camera images as our input data\n",
    "    X = data_df['img'].values\n",
    "    #and our steering commands as our output data\n",
    "    y = data_df['ang'].values\n",
    "    \n",
    "    #now we can split the data into a training (80), testing(20), and validation set\n",
    "    #thanks scikit learn\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "    return X_train, X_valid, y_train, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    NVIDIA model used\n",
    "    Image normalization to avoid saturation and make gradients work better.\n",
    "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Drop out (0.5)\n",
    "    Fully connected: neurons: 100, activation: ELU\n",
    "    Fully connected: neurons: 50, activation: ELU\n",
    "    Fully connected: neurons: 10, activation: ELU\n",
    "    Fully connected: neurons: 1 (output)\n",
    "\n",
    "    # the convolution layers are meant to handle feature engineering\n",
    "    the fully connected layer for predicting the steering angle.\n",
    "    dropout avoids overfitting\n",
    "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem. \n",
    "    \"\"\"\n",
    "    # Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
    "    # the three color channels: R, G, and B\n",
    "   \n",
    "\n",
    "    img_input = layers.Input(shape=(66, 200, 3))\n",
    "    x = layers.Conv2D(24, 5, (2, 2), activation='relu')(img_input)\n",
    "    #x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(36, 5,(2, 2), activation='relu')(x)\n",
    "    #x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(48, 5,(2, 2), activation='relu')(x)\n",
    "    #x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(64, 3,(1, 1), activation='relu')(x)\n",
    "    #x = layers.MaxPooling2D(1)(x)\n",
    "    x = layers.Conv2D(64,1, (2, 2), activation='relu')(x)\n",
    "    #x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    x = layers.Dense(50, activation='relu')(x)\n",
    "    x = layers.Dense(10, activation='relu')(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = Model(img_input, output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    \"\"\"\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Flow training images in batches of 20 using train_datagen generator\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe=data_df[:len(X_train)],\n",
    "            directory=None,\n",
    "            x_col='img',\n",
    "            y_col='ang',\n",
    "            target_size=(66, 200),\n",
    "            classes=None,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=100,\n",
    "            save_format=\"jpg\",\n",
    "        )\n",
    "\n",
    "    # Flow validation images in batches of 20 using val_datagen generator\n",
    "    valid_generator = val_datagen.flow_from_dataframe(\n",
    "            dataframe=data_df[len(X_train):],\n",
    "            directory=None,\n",
    "            x_col='img',\n",
    "            y_col='ang',\n",
    "            target_size=(66, 200),\n",
    "            classes=None,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=100,\n",
    "            save_format=\"jpg\",\n",
    "        )\n",
    "    print(train_generator)\n",
    "   \n",
    "    filepath_f = './Autopilot.h5'\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam',metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    model.fit_generator(train_generator,\n",
    "                        steps_per_epoch=300,\n",
    "                        epochs=10,\n",
    "                        max_queue_size=1,\n",
    "                        validation_data=valid_generator,\n",
    "                        validation_steps=50,\n",
    "                        verbose=1)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#for command line args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "   \n",
    "\n",
    "    #load data\n",
    "    data = load_data()\n",
    "    #build model\n",
    "    model = build_model()\n",
    "    #train model on data, it saves as model.h5 \n",
    "    train_model(model, *data)\n",
    "    model.save('Autopilot.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 66, 200, 3)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 10, 64)         4160      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               128100    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 232,251\n",
      "Trainable params: 232,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 51060 validated image filenames.\n",
      "Found 12765 validated image filenames.\n",
      "<tensorflow.python.keras.preprocessing.image.DataFrameIterator object at 0x0000017F577F0310>\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 183s 4s/step - loss: 826.0205 - accuracy: 0.0278 - val_loss: 281.7373 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 175s 4s/step - loss: 783.4220 - accuracy: 0.0252 - val_loss: 262.1028 - val_accuracy: 0.0136\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 161s 3s/step - loss: 749.4097 - accuracy: 0.0216 - val_loss: 302.1482 - val_accuracy: 0.0244\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 161s 3s/step - loss: 749.7979 - accuracy: 0.0318 - val_loss: 303.7418 - val_accuracy: 0.0300\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 180s 4s/step - loss: 785.7843 - accuracy: 0.0296 - val_loss: 271.6209 - val_accuracy: 0.0332\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 165s 3s/step - loss: 672.1934 - accuracy: 0.0240 - val_loss: 279.6550 - val_accuracy: 0.0296\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 247s 5s/step - loss: 689.3311 - accuracy: 0.0294 - val_loss: 298.2183 - val_accuracy: 0.0336\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 221s 4s/step - loss: 732.8719 - accuracy: 0.0264 - val_loss: 370.8836 - val_accuracy: 0.0322\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 218s 4s/step - loss: 659.4191 - accuracy: 0.0256 - val_loss: 319.2193 - val_accuracy: 0.0196\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 209s 4s/step - loss: 728.5842 - accuracy: 0.0262 - val_loss: 328.7625 - val_accuracy: 0.0240\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
